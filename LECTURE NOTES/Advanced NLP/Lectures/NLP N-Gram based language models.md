## n-gram LM and Markov assumption
- Simplest LM is based on sequences of words, the n-gram
- Markov chain assumption: $P(w_n|w_1, ..., w_{n-1} \approx P(w_n|w_{n-m}, .., w_{n-1})$
- The order of the LM is defined by m often: